{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from sklearn import model_selection\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"/Users/aysjajohnson/Desktop/ARC-master/data/training/\"\n",
    "test_path = \"/Users/aysjajohnson/Desktop/ARC-master/data/evaluation/\"\n",
    "\n",
    "def load_task(task_filename, path = training_path):\n",
    "    with open(path + task_filename, 'r') as f:\n",
    "        task = json.load(f)    \n",
    "    return task\n",
    "\n",
    "def flatten_task(task):\n",
    "    \"\"\"given a json format for a task, return all grids in a list\"\"\"\n",
    "    grids_list = []\n",
    "    for grid in task[\"train\"]:\n",
    "        grids_list.append(grid_to_str(grid[\"input\"]))\n",
    "        grids_list.append(grid_to_str(grid[\"output\"]))\n",
    "    for grid in task[\"test\"]:\n",
    "        grids_list.append(grid_to_str(grid[\"input\"]))\n",
    "        grids_list.append(grid_to_str(grid[\"output\"]))\n",
    "    return grids_list\n",
    "\n",
    "def plot_task(task):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    \n",
    "    cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    \n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    n_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(n_train+1, 2, figsize=(10, 10))\n",
    "    for i in range(n_train):\n",
    "        axs[i, 0].imshow(task['train'][i]['input'], cmap=cmap, norm=norm)\n",
    "        axs[i, 0].axis('off')\n",
    "        axs[i, 0].set_title('Train Input')\n",
    "        axs[i, 1].imshow(task['train'][i]['output'], cmap=cmap, norm=norm)\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 1].set_title('Train Output')\n",
    "    axs[n_train, 0].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n",
    "    axs[n_train, 0].axis('off')\n",
    "    axs[n_train, 0].set_title('Test Input')\n",
    "    axs[n_train, 1].imshow(task['test'][0]['output'], cmap=cmap, norm=norm)\n",
    "    axs[n_train, 1].axis('off')\n",
    "    axs[n_train, 1].set_title('Test Output')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "def str_to_grid(grid):\n",
    "    new_grid = []\n",
    "    str_ = grid.split(\"|\")\n",
    "    for s in str_:\n",
    "        if s == '':\n",
    "            continue\n",
    "        new_grid.append(list(map(int, s)))\n",
    "    return new_grid\n",
    "\n",
    "def grid_to_str(grid):\n",
    "    new_grid = ''\n",
    "    for row in grid:\n",
    "        for num in row:\n",
    "            new_grid += str(num)\n",
    "        new_grid+='|'\n",
    "    return new_grid[:-1]\n",
    "    \n",
    "\n",
    "def plot_grid(grid):\n",
    "    cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    \n",
    "    \n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(6, 6), squeeze=False)\n",
    "    axs[0, 0].imshow(grid, cmap=cmap, norm=norm)\n",
    "    axs[0, 0].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_grids(grids):\n",
    "    cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    n_grids = len(grids)\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, n_grids, figsize=(6, 6), squeeze=False)\n",
    "    for i in range(n_grids):\n",
    "        axs[0, i].imshow(grids[i], cmap=cmap, norm=norm)\n",
    "        axs[0, i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading flattened training and evaluation (test) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = list(map(load_task, sorted(os.listdir(training_path))[1:]))\n",
    "train_tasks = list(map(flatten_task, train_tasks))\n",
    "train_tasks_str = [item for sublist in train_tasks for item in sublist]\n",
    "train_tasks = list(map(str_to_grid, train_tasks_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tasks = list(map(lambda x: load_task(x, path=test_path), sorted(os.listdir(test_path))[1:]))\n",
    "test_tasks = list(map(flatten_task, test_tasks))\n",
    "test_tasks_str = [item for sublist in test_tasks for item in sublist]\n",
    "test_tasks = list(map(str_to_grid, test_tasks_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest task in training and test is 30x30\n",
    "len(str_to_grid(max(train_tasks_str, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, pad data and then mask (token = 11)\n",
    "def pad_data(grid, padding_token = 0):\n",
    "    \"\"\"given a grid, return a 30x30 grid padded with 0s\"\"\"\n",
    "    # int_grid = np.asarray(copy.deepcopy(grid)).astype('int32') \n",
    "    nrows = len(grid)\n",
    "    ncols = len(grid[0])\n",
    "    if nrows == 30 and ncols == 30:\n",
    "        return np.asarray(grid)\n",
    "    else:\n",
    "        new_grid = np.ones((30,30)).astype('int32')*padding_token\n",
    "        new_grid[:nrows, :ncols] = grid\n",
    "    return new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might want to have this lognormal distributed or something, since most of the cells happen in the first few lines\n",
    "def mask_data(grid, percent_mask = 0.3):\n",
    "    \"\"\"given a grid, return a masked grid -- mask token = 11\"\"\"\n",
    "    masked_grid = copy.deepcopy(grid)\n",
    "    mask = np.random.rand(30,30)\n",
    "    masked_grid[np.where(mask < percent_mask)] = 11\n",
    "    return masked_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_train = list(map(pad_data, train_tasks))\n",
    "pad_test = list(map(pad_data, test_tasks))\n",
    "mask_train = list(map(mask_data, pad_train))\n",
    "mask_test = list(map(mask_data, pad_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(mask_train, pad_train, test_size = 0.1)\n",
    "X_test, y_test = mask_test, pad_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, implement heuristic based approach to the masking problem: for any 3x3 grid, fill in the missing cells with the dominant color of that grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_fill(grid, window=3):\n",
    "    \"\"\"given a masked grid, return a best guess grid given the dominant color of each 3x3 section\"\"\"\n",
    "    pred_grid = copy.deepcopy(grid)\n",
    "    for i in list(range(30))[::window]:\n",
    "        for j in list(range(30))[::window]:\n",
    "            most_common_colors = Counter(grid[i:i+window, j:j+window].flatten()).most_common(3)\n",
    "            dom_color = most_common_colors[0][0]\n",
    "            if dom_color == 11.0:\n",
    "            # if there are no other dominant colors (3x3 is all masks, then set the dominant color to black)\n",
    "                if len(most_common_colors) < 2:\n",
    "                    dom_color = 0.0\n",
    "                else:\n",
    "                    dom_color = most_common_colors[1][0]\n",
    "            pred_grid[i:i+3,j:j+3][np.where(grid[i:i+window, j:j+window] == 11.0)] = dom_color\n",
    "    return pred_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_binary(pred_grid, test_grid):\n",
    "    \"\"\"return percentage of correct grid cells (match or not)\"\"\"\n",
    "    return np.sum(pred_grid == test_grid)/900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_color(pred_grid, test_grid):\n",
    "    \"\"\"return precentage of correct grid cells for colored cells only\"\"\"\n",
    "    color_pred = pred_grid[np.where(test_grid!=0)]\n",
    "    color_val = test_grid[np.where(test_grid!=0)]\n",
    "    return np.sum(color_pred == color_val)/len(color_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = list(map(max_fill, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "predictions = list(zip(pred_train, y_train))\n",
    "for pred in predictions:\n",
    "    score_list.append(score_binary(pred[0], pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865192376842862"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline is ~80% (depending on mask parameter)\n",
    "np.mean(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "predictions = list(zip(pred_train, y_train))\n",
    "for pred in predictions:\n",
    "    score_list.append(score_color(pred[0], pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = [score for score in score_list if str(score) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7693854128139594"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from mlm_pytorch import MLM\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowing code from: https://github.com/lucidrains/mlm-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask token = 11, pad token = 12, | = 13, sos = 14, eos = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_walls(str_grid):\n",
    "    \"\"\"given a grid in string format, remove the | tokens\"\"\"\n",
    "    return [x if x!='|' else '13' for x in str_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_float(str_grid):\n",
    "    \"\"\"given a list of strings, return a list of floats\"\"\"\n",
    "    return [float(i) for i in str_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_data(grids, padding_token=12):\n",
    "    \"\"\"given a list of all grids, return list of strings with eos/sos tokens\"\"\"\n",
    "    padded_grids = list(map(lambda x: pad_data(x,padding_token), grids))\n",
    "    str_grids = list(map(grid_to_str, padded_grids))\n",
    "    tokenized_grids = list(map(replace_walls, str_grids))\n",
    "    sos = list(map(lambda x: ['14'] + x, tokenized_grids))\n",
    "    eos = list(map(lambda x: x + ['15'], sos))\n",
    "    float_grids = list(map(str_to_float, eos))\n",
    "    return list(map(torch.LongTensor, float_grids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tasks = transformer_data(train_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14,  0,  7,  ...,  1,  2, 15])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the data class\n",
    "# I think because masking happens later, you want just the padded data here \n",
    "class ARCDataset(Dataset):\n",
    "    \"\"\"ARC masked dataset.\"\"\"\n",
    "\n",
    "    # def __init__(self, csv_file, root_dir, transform=None):\n",
    "    def __init__(self, tasks, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.ARC_data = tasks\n",
    "        self.root_dir = training_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ARC_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = self.ARC_data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARC_dataset = ARCDataset(transformer_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the language model\n",
    "from reformer_pytorch import ReformerLM, Autopadder\n",
    "\n",
    "transformer = ReformerLM(\n",
    "    num_tokens = 15,\n",
    "    dim = 512,\n",
    "    depth = 1,\n",
    "    max_seq_len = 1822\n",
    "    # max_seq_len = 2048\n",
    ")\n",
    "\n",
    "model = Autopadder(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1556e5246ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARC_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/mlm_pytorch/mlm_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# get generator output and get mlm loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/reformer_pytorch/autopadder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_attn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aysjajohnson/opt/anaconda3/envs/cogsci21/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# plugin the language model into the MLM trainer\n",
    "\n",
    "trainer = MLM(\n",
    "    model,\n",
    "    mask_token_id = 11,          # the token id reserved for masking\n",
    "    pad_token_id = 12,           # the token id for padding\n",
    "    mask_prob = 0.15,           # masking probability for masked language modeling\n",
    "    replace_prob = 0.90,        # ~10% probability that token will not be masked, but included in loss, as detailed in the epaper\n",
    "    mask_ignore_token_ids = [13,14,15]  # other tokens to exclude from masking, include the [cls] and [sep] here\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "\n",
    "opt = Adam(trainer.parameters(), lr=3e-4)\n",
    "\n",
    "# one training step (do this for many steps in a for loop, getting new `data` each time)\n",
    "loss = 0\n",
    "for i in range(len(ARC_dataset)):\n",
    "    if i%10 == 0: \n",
    "        print(i, loss)\n",
    "    data = torch.unsqueeze(ARC_dataset[0], 0)\n",
    "    loss = trainer(data)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "# after much training, the model should have improved for downstream tasks\n",
    "\n",
    "torch.save(transformer, f'./ARC-model_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17080,  3317, 11094,  ..., 15304, 16984, 15031],\n",
      "        [ 3411,  9744, 16893,  ..., 14923,   779, 10869],\n",
      "        [ 4334,  8292,  2010,  ..., 12168, 18736, 12822],\n",
      "        ...,\n",
      "        [11606,  7297, 11082,  ..., 18047,   163, 11690],\n",
      "        [14243,   909,  9955,  ...,  6297, 19983, 17896],\n",
      "        [10394, 10844,  7049,  ..., 17132, 10793,  8393]])\n",
      "prediction:  tensor([[[ 4.1205e-01,  4.3679e-02,  6.3976e-03,  ...,  6.7762e-01,\n",
      "          -5.7868e-01, -1.2010e-01],\n",
      "         [ 3.2005e-01, -3.6025e-02, -4.6149e-02,  ...,  1.0616e-01,\n",
      "          -8.7187e-01,  4.7881e-01],\n",
      "         [ 5.5489e-01,  7.4331e-02, -7.1933e-01,  ...,  7.0006e-01,\n",
      "           4.2986e-01,  2.6815e-02],\n",
      "         ...,\n",
      "         [-2.1083e-01, -6.1884e-01, -1.1903e-01,  ..., -1.0906e+00,\n",
      "          -1.3950e-01, -4.3852e-02],\n",
      "         [ 1.7213e-01, -8.2585e-01, -4.4409e-01,  ...,  5.9111e-02,\n",
      "          -3.4356e-01, -5.5135e-01],\n",
      "         [ 7.7929e-01,  6.4803e-02,  1.3746e-01,  ..., -4.0445e-02,\n",
      "           2.4477e-01, -4.1555e-02]],\n",
      "\n",
      "        [[ 6.9699e-01,  1.1080e+00,  1.9068e-01,  ...,  3.5701e-01,\n",
      "          -1.2377e-01,  1.0712e-01],\n",
      "         [ 5.8280e-01,  4.4748e-02, -4.8018e-01,  ...,  4.6504e-02,\n",
      "           3.9330e-01, -2.5173e-02],\n",
      "         [ 4.6234e-01,  4.0657e-01, -1.4096e+00,  ...,  1.2997e-01,\n",
      "           4.8269e-01,  4.6087e-01],\n",
      "         ...,\n",
      "         [ 5.8345e-01, -1.9915e-01, -3.3378e-01,  ..., -8.2357e-01,\n",
      "          -5.5346e-01, -3.1269e-01],\n",
      "         [ 9.5082e-01, -7.7396e-01,  2.7394e-01,  ..., -5.9286e-02,\n",
      "           5.5098e-01, -3.4504e-01],\n",
      "         [ 3.3259e-01, -8.0191e-02,  3.3205e-01,  ..., -8.5579e-03,\n",
      "          -7.5980e-01,  4.7571e-01]],\n",
      "\n",
      "        [[ 5.3580e-01,  4.7107e-01, -6.0614e-01,  ...,  1.0444e+00,\n",
      "          -6.2550e-01, -1.7896e-01],\n",
      "         [ 3.7761e-01,  7.9448e-01, -5.1011e-01,  ...,  4.7125e-01,\n",
      "           4.6135e-02,  4.9495e-01],\n",
      "         [ 1.4448e-02,  1.9318e-01, -6.5817e-01,  ...,  5.1941e-01,\n",
      "          -3.2925e-01,  9.4525e-01],\n",
      "         ...,\n",
      "         [ 5.3227e-01, -6.7507e-01,  2.9170e-01,  ..., -5.0643e-01,\n",
      "           1.7960e-01, -3.1407e-01],\n",
      "         [ 2.1304e-01, -8.1340e-01,  8.9775e-02,  ...,  9.2713e-02,\n",
      "          -2.7939e-01, -1.5802e-01],\n",
      "         [ 3.3732e-01,  5.5992e-02,  1.5807e-01,  ..., -3.9714e-01,\n",
      "           1.0561e-01, -1.4054e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4592e-01,  1.7763e-01, -4.2696e-01,  ...,  5.6024e-01,\n",
      "          -1.1338e+00,  3.9748e-02],\n",
      "         [-2.0677e-01,  2.5070e-01, -4.9519e-01,  ...,  3.0575e-01,\n",
      "          -4.4936e-01,  5.4254e-02],\n",
      "         [ 8.9111e-01,  1.0288e+00, -1.3271e+00,  ...,  4.0459e-01,\n",
      "          -2.6510e-02,  1.4236e+00],\n",
      "         ...,\n",
      "         [ 2.1248e-02, -5.0996e-01,  1.1119e-01,  ..., -2.0454e-01,\n",
      "          -4.0751e-01, -3.6578e-01],\n",
      "         [ 8.6371e-01, -7.6160e-01, -5.2185e-01,  ...,  3.1206e-01,\n",
      "           2.6395e-01, -9.7748e-01],\n",
      "         [ 9.5564e-01,  4.5600e-01,  2.6443e-01,  ...,  5.5315e-01,\n",
      "           2.3571e-02,  5.4100e-01]],\n",
      "\n",
      "        [[ 3.8700e-01,  2.6600e-01, -7.1641e-01,  ...,  9.3844e-01,\n",
      "          -2.3609e-01,  5.9143e-02],\n",
      "         [ 3.2171e-01, -2.8240e-02, -4.5834e-02,  ...,  1.0744e-01,\n",
      "          -8.7081e-01,  4.7843e-01],\n",
      "         [ 1.6586e-01, -1.3997e-01, -1.1771e+00,  ...,  9.6517e-01,\n",
      "           4.8833e-01,  1.3096e+00],\n",
      "         ...,\n",
      "         [ 1.2547e-02, -7.1185e-01,  7.9020e-02,  ..., -3.2220e-01,\n",
      "          -1.2806e+00, -2.5674e-01],\n",
      "         [ 2.8570e-01, -3.7849e-01, -3.5787e-01,  ..., -1.9571e-01,\n",
      "           1.1328e+00, -9.8984e-01],\n",
      "         [ 9.9520e-01, -2.6642e-01, -2.4505e-02,  ..., -3.2795e-01,\n",
      "           5.2671e-01,  3.9378e-01]],\n",
      "\n",
      "        [[ 9.1747e-01,  3.7199e-01, -1.1735e+00,  ...,  2.3976e-01,\n",
      "          -5.2904e-01, -3.0363e-01],\n",
      "         [ 3.8355e-01,  3.9301e-01, -3.2973e-01,  ..., -3.7673e-02,\n",
      "           6.5227e-01,  2.0480e-01],\n",
      "         [-1.7265e-01, -3.3785e-02, -9.9047e-01,  ...,  1.2918e+00,\n",
      "           4.5517e-01,  2.6432e-01],\n",
      "         ...,\n",
      "         [ 3.7176e-01, -1.4004e+00, -5.1057e-01,  ...,  9.8804e-02,\n",
      "           5.9139e-02, -5.5602e-01],\n",
      "         [ 4.3765e-01, -6.8115e-01, -9.3756e-02,  ...,  1.6777e-01,\n",
      "           9.4235e-01,  1.8534e-01],\n",
      "         [ 3.5355e-01, -2.2360e-01,  2.3197e-01,  ..., -3.1794e-01,\n",
      "           1.1509e-01,  4.0740e-01]]], grad_fn=<AddBackward0>)\n",
      "grid:  tensor([[    0,  3317,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0, 10869],\n",
      "        [    0,     0,  2010,  ...,     0, 18736, 12822],\n",
      "        ...,\n",
      "        [11606,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,   909,     0,  ...,  6297,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]])\n",
      "torch.Size([10, 1024, 20000]) torch.Size([10, 1024])\n"
     ]
    }
   ],
   "source": [
    "transformer = ReformerLM(\n",
    "    num_tokens = 20000,\n",
    "    dim = 512,\n",
    "    depth = 1,\n",
    "    max_seq_len = 1024\n",
    ")\n",
    "\n",
    "# plugin the language model into the MLM trainer\n",
    "\n",
    "trainer = MLM(\n",
    "    transformer,\n",
    "    mask_token_id = 2,          # the token id reserved for masking\n",
    "    pad_token_id = 0,           # the token id for padding\n",
    "    mask_prob = 0.15,           # masking probability for masked language modeling\n",
    "    replace_prob = 0.90,        # ~10% probability that token will not be masked, but included in loss, as detailed in the epaper\n",
    "    mask_ignore_token_ids = []  # other tokens to exclude from masking, include the [cls] and [sep] here\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "\n",
    "opt = Adam(trainer.parameters(), lr=3e-4)\n",
    "\n",
    "# one training step (do this for many steps in a for loop, getting new `data` each time)\n",
    "\n",
    "data = torch.randint(0, 20000, (10, 1024))\n",
    "print(data)\n",
    "\n",
    "loss = trainer(data)\n",
    "# loss.backward()\n",
    "# opt.step()\n",
    "# opt.zero_grad()\n",
    "\n",
    "# after much training, the model should have improved for downstream tasks\n",
    "\n",
    "# torch.save(transformer, f'./pretrained-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_data(train_tasks[0], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
